{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interior-glenn",
   "metadata": {},
   "source": [
    "# 가사 생성 RNN 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-attendance",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fourth-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['[Hook]', \"I've been down so long, it look like up to me\", 'They look up to me']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "txt_file_path = 'lyricist/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-swimming",
   "metadata": {},
   "source": [
    "## 데이터 정제하기\n",
    "\n",
    "- 소설과 달리 가사는 1절, 2절이 비슷한 경우가 많다. 따라서 중복 문장을 처리해줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-minute",
   "metadata": {},
   "source": [
    "### 특수 문자 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bound-vector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('(', 11202),\n",
       " (')', 11199),\n",
       " ('-', 8962),\n",
       " ('\"', 2663),\n",
       " ('’', 2642),\n",
       " ('\\t', 1708),\n",
       " ('[', 1606),\n",
       " (']', 1604),\n",
       " (';', 1110),\n",
       " (':', 712),\n",
       " ('*', 593),\n",
       " ('—', 413),\n",
       " ('|', 165),\n",
       " ('“', 159),\n",
       " ('”', 158),\n",
       " ('é', 88),\n",
       " ('í', 83),\n",
       " ('&', 77),\n",
       " ('á', 70),\n",
       " ('+', 67),\n",
       " ('‚', 55),\n",
       " ('_', 54),\n",
       " ('/', 52),\n",
       " ('`', 51),\n",
       " ('ä', 46),\n",
       " ('{', 43),\n",
       " ('}', 41),\n",
       " ('ú', 36),\n",
       " ('ó', 35),\n",
       " ('à', 35),\n",
       " ('¿', 28),\n",
       " ('è', 24),\n",
       " ('ß', 23),\n",
       " ('ð', 22),\n",
       " ('â', 20),\n",
       " ('¬', 19),\n",
       " ('ñ', 18),\n",
       " ('ù', 17),\n",
       " ('‘', 15),\n",
       " ('√', 14),\n",
       " ('ö', 14),\n",
       " ('ã', 12),\n",
       " ('ü', 11),\n",
       " ('$', 11),\n",
       " ('©', 10),\n",
       " ('ë', 8),\n",
       " ('ç', 7),\n",
       " ('#', 6),\n",
       " ('ê', 6),\n",
       " ('∑', 6),\n",
       " ('¨', 6),\n",
       " ('¡', 5),\n",
       " ('\\ufeff', 5),\n",
       " ('–', 4),\n",
       " ('±', 4),\n",
       " ('>', 3),\n",
       " ('ì', 3),\n",
       " ('å', 3),\n",
       " ('´', 2),\n",
       " ('…', 2),\n",
       " ('õ', 2),\n",
       " ('%', 2),\n",
       " ('=', 2),\n",
       " ('ª', 1),\n",
       " ('@', 1),\n",
       " ('′', 1),\n",
       " ('″', 1),\n",
       " ('\\xad', 1),\n",
       " ('ô', 1),\n",
       " ('«', 1),\n",
       " ('»', 1),\n",
       " ('≠', 1),\n",
       " ('ƒ', 1),\n",
       " ('¶', 1),\n",
       " ('≥', 1),\n",
       " ('þ', 1),\n",
       " ('ò', 1),\n",
       " ('¢', 1),\n",
       " ('†', 1),\n",
       " ('∆', 1),\n",
       " ('•', 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_word = defaultdict(int)\n",
    "alpha = [chr(x) for x in range(ord('a'), ord('z')+1)] + [\"'\", \",\", \".\", \"!\", \"?\", \" \"] + [str(i) for i in range(10)]\n",
    "\n",
    "for raw in raw_corpus:\n",
    "    raw = raw.lower()\n",
    "    for r in raw:\n",
    "        if r not in alpha:\n",
    "            special_word[r] += 1\n",
    "\n",
    "Counter.most_common(special_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-electric",
   "metadata": {},
   "source": [
    "### 정제 및 중복 문장 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-surrey",
   "metadata": {},
   "source": [
    "메타문자: ^$.*+?=!:|\\/()[]{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "printable-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = set()\n",
    "for raw in raw_corpus:\n",
    "    raw = raw.lower().strip()\n",
    "    raw = raw.replace('f***', 'fuck')\n",
    "    raw = re.sub(r\"(\\[|\\()(\\w+)(\\]|\\))\", r\"\", raw)\n",
    "    raw = re.sub(r\"\\t\\[\\]\\(\\)-;\", r\" \", raw)\n",
    "    raw = raw.replace('\\ufeff', '')\n",
    "    raw = re.sub(r'\"‘“”\\`', r\"'\", raw)\n",
    "    raw = re.sub(r\"([\\?.!,'])\", r\" \\1 \", raw)\n",
    "    raw = re.sub(r'[\" \"]+', \" \", raw)\n",
    "    if len(set(list(raw)) - set(alpha)) > 0:\n",
    "        continue\n",
    "    \n",
    "    if len(set(raw)) < 4:\n",
    "        continue\n",
    "    \n",
    "    raw = raw.strip()\n",
    "    raw = '<start> ' + raw + ' <end>'\n",
    "    \n",
    "    if len(raw.split()) > 16:\n",
    "        continue\n",
    "            \n",
    "    corpus.add(raw)\n",
    "\n",
    "corpus = list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indoor-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> i know i got the green light <end>',\n",
       " '<start> i may have been only three <end>',\n",
       " '<start> ben franklin dizzy nigga <end>',\n",
       " '<start> i can show someone else <end>',\n",
       " '<start> and the darkness is lighter now <end>',\n",
       " '<start> ha , and i better come split it <end>',\n",
       " \"<start> see me when i drop when i won ' t flop <end>\",\n",
       " '<start> yeah im eatin but i got a tapeworm in my tummy oh <end>',\n",
       " '<start> my enemies want to be friends with my other enemies <end>',\n",
       " '<start> i looked at my haggard face in the bathroom light <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developmental-jacket",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91611"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-crime",
   "metadata": {},
   "source": [
    "### 사용된 단어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "young-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = defaultdict(int)\n",
    "for c in corpus:\n",
    "    for word in c.split():\n",
    "        words[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-atlantic",
   "metadata": {},
   "source": [
    "#### 총 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anticipated-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-bidder",
   "metadata": {},
   "source": [
    "#### 가장 많이 사용된 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "turned-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start>', 91611),\n",
       " ('<end>', 91611),\n",
       " (\"'\", 28906),\n",
       " (',', 27425),\n",
       " ('i', 27380),\n",
       " ('the', 25191),\n",
       " ('you', 20323),\n",
       " ('and', 15138),\n",
       " ('a', 13050),\n",
       " ('to', 12964),\n",
       " ('it', 9613),\n",
       " ('me', 9305),\n",
       " ('my', 9055),\n",
       " ('in', 8244),\n",
       " ('that', 7079),\n",
       " ('s', 6390),\n",
       " ('of', 6053),\n",
       " ('t', 6036),\n",
       " ('.', 5939),\n",
       " ('on', 5699),\n",
       " ('your', 5546),\n",
       " ('we', 4951),\n",
       " ('like', 4677),\n",
       " ('is', 4565),\n",
       " ('all', 4524),\n",
       " ('m', 4006),\n",
       " ('be', 3911),\n",
       " ('for', 3902),\n",
       " ('with', 3857),\n",
       " ('so', 3855),\n",
       " ('but', 3702),\n",
       " ('up', 3581),\n",
       " ('just', 3421),\n",
       " ('can', 3342),\n",
       " ('know', 3292),\n",
       " ('they', 3239),\n",
       " ('this', 3205),\n",
       " ('got', 3114),\n",
       " ('she', 2991),\n",
       " ('when', 2956),\n",
       " ('love', 2940),\n",
       " ('what', 2887),\n",
       " ('no', 2846),\n",
       " ('?', 2844),\n",
       " ('get', 2718),\n",
       " ('he', 2691),\n",
       " ('was', 2690),\n",
       " ('don', 2688),\n",
       " ('do', 2585),\n",
       " ('now', 2421),\n",
       " ('if', 2384),\n",
       " ('out', 2251),\n",
       " ('baby', 2153),\n",
       " ('oh', 2049),\n",
       " ('go', 2045),\n",
       " ('re', 2038),\n",
       " ('her', 1985),\n",
       " ('!', 1977),\n",
       " ('down', 1962),\n",
       " ('there', 1952),\n",
       " ('one', 1894),\n",
       " ('yeah', 1891),\n",
       " ('see', 1831),\n",
       " ('ll', 1818),\n",
       " ('at', 1776),\n",
       " ('not', 1774),\n",
       " ('from', 1728),\n",
       " ('have', 1686),\n",
       " ('let', 1660),\n",
       " ('cause', 1630),\n",
       " ('say', 1615),\n",
       " ('make', 1614),\n",
       " ('are', 1592),\n",
       " ('never', 1571),\n",
       " ('as', 1571),\n",
       " ('want', 1570),\n",
       " ('back', 1532),\n",
       " ('come', 1507),\n",
       " ('time', 1501),\n",
       " ('how', 1467),\n",
       " ('will', 1451),\n",
       " ('take', 1360),\n",
       " ('man', 1307),\n",
       " ('then', 1292),\n",
       " ('his', 1268),\n",
       " ('girl', 1228),\n",
       " ('way', 1219),\n",
       " ('u', 1202),\n",
       " ('right', 1196),\n",
       " ('im', 1181),\n",
       " ('who', 1179),\n",
       " ('some', 1179),\n",
       " ('here', 1124),\n",
       " ('wanna', 1116),\n",
       " ('ve', 1114),\n",
       " ('could', 1114),\n",
       " ('tell', 1107),\n",
       " ('need', 1099),\n",
       " ('them', 1078),\n",
       " ('where', 1070)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(words).most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-belfast",
   "metadata": {},
   "source": [
    "## 가사 생성 객체 정의\n",
    "\n",
    "corpus와 Keras Model을 받아, 모델을 훈련하고, 결과를 반환하는 객체 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "associate-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateLyrics():\n",
    "    def __init__(self, corpus, Model):\n",
    "        self.corpus = corpus\n",
    "        self.tensor, self.tokenizer = self.tokenize(self.corpus)\n",
    "        self.x, self.y = self.tensor[:, :-1], self.tensor[:, 1:]\n",
    "        self.train_x, self.test_x, self.train_y, self.test_y = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
    "        self.BUFFER_SIZE = len(self.x)\n",
    "        self.BATCH_SIZE = 256\n",
    "        self.dataset, self.test_dataset = self.make_dataset(self.train_x, self.test_x, self.train_y, self.test_y)\n",
    "        \n",
    "        self.embedding_size = 256\n",
    "        self.hidden_size = 1024\n",
    "        self.model = Model(self.tokenizer.num_words + 1, self.embedding_size , self.hidden_size)\n",
    "        \n",
    "    def tokenize(self, corpus):\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=1000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "        )\n",
    "        tokenizer.fit_on_texts(corpus)\n",
    "        tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "        return tensor, tokenizer\n",
    "    \n",
    "    def make_dataset(self, train_x, test_x, train_y, test_y):\n",
    "        steps_per_epoch = self.BUFFER_SIZE // self.BATCH_SIZE\n",
    "\n",
    "        VOCAB_SIZE = self.tokenizer.num_words + 1   \n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.train_x, self.train_y))\n",
    "        dataset = dataset.shuffle(self.BUFFER_SIZE)\n",
    "        dataset = dataset.batch(self.BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((self.test_x, self.test_y))\n",
    "        test_dataset = test_dataset.shuffle(self.BUFFER_SIZE)\n",
    "        test_dataset = test_dataset.batch(self.BATCH_SIZE, drop_remainder=True)\n",
    "        return dataset, test_dataset\n",
    "    \n",
    "    \n",
    "    def fit(self, epoch=5):\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True,\n",
    "            reduction='none'\n",
    "        )\n",
    "\n",
    "        self.model.compile(loss=loss, optimizer=optimizer)\n",
    "        hist = self.model.fit(self.dataset, epochs=epoch, validation_data=self.test_dataset)\n",
    "        return hist\n",
    "        \n",
    "        \n",
    "    def generate_text(self, init_sentence=\"<start>\", max_len=20):\n",
    "        test_input = self.tokenizer.texts_to_sequences([init_sentence])\n",
    "        test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "        end_token = self.tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "        while True:\n",
    "            predict = self.model(test_tensor) \n",
    "            predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "            test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "            if predict_word.numpy()[0] == end_token:\n",
    "                break\n",
    "            if test_tensor.shape[1] >= max_len:\n",
    "                break\n",
    "\n",
    "        generated = \"\"\n",
    "        for word_index in test_tensor[0].numpy():\n",
    "            generated += self.tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-shannon",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inappropriate-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True, recurrent_dropout=0.5)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True, recurrent_dropout=0.5)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-prize",
   "metadata": {},
   "source": [
    "### 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "decimal-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_sizes = [64,128,256,512]\n",
    "hidden_sizes = [256,512,1024,2408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "starting-halifax",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 사이즈:  64 hidden size:  256\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 122s 409ms/step - loss: 3.3100 - val_loss: 2.4268\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.3770 - val_loss: 2.2801\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.2511 - val_loss: 2.2179\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.1894 - val_loss: 2.1781\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.1484 - val_loss: 2.1490\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.1018 - val_loss: 2.1280\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0622 - val_loss: 2.1157\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0236 - val_loss: 2.1039\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9805 - val_loss: 2.0973\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.9469 - val_loss: 2.0946\n",
      "임베딩 사이즈:  64 hidden size:  512\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 117s 391ms/step - loss: 3.3109 - val_loss: 2.4263\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.3763 - val_loss: 2.2799\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 118s 414ms/step - loss: 2.2606 - val_loss: 2.2150\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 117s 410ms/step - loss: 2.1934 - val_loss: 2.1748\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 114s 397ms/step - loss: 2.1429 - val_loss: 2.1447\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 114s 400ms/step - loss: 2.0961 - val_loss: 2.1300\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0561 - val_loss: 2.1168\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0183 - val_loss: 2.1045\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9837 - val_loss: 2.0994\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9406 - val_loss: 2.0955\n",
      "임베딩 사이즈:  64 hidden size:  1024\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 116s 389ms/step - loss: 3.3228 - val_loss: 2.4185\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.3739 - val_loss: 2.2791\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 116s 406ms/step - loss: 2.2613 - val_loss: 2.2178\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 112s 390ms/step - loss: 2.1897 - val_loss: 2.1810\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.1398 - val_loss: 2.1513\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 113s 396ms/step - loss: 2.0965 - val_loss: 2.1286\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.0552 - val_loss: 2.1159\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.0208 - val_loss: 2.1040\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 1.9823 - val_loss: 2.0982\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 1.9450 - val_loss: 2.0960\n",
      "임베딩 사이즈:  64 hidden size:  2408\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 120s 402ms/step - loss: 3.3282 - val_loss: 2.4255\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.3883 - val_loss: 2.2878\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 2.2692 - val_loss: 2.2199\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 117s 408ms/step - loss: 2.1930 - val_loss: 2.1770\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 124s 433ms/step - loss: 2.1411 - val_loss: 2.1523\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 127s 444ms/step - loss: 2.1036 - val_loss: 2.1288\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 114s 400ms/step - loss: 2.0647 - val_loss: 2.1156\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.0294 - val_loss: 2.1065\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 114s 399ms/step - loss: 1.9843 - val_loss: 2.0968\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 1.9565 - val_loss: 2.0945\n",
      "임베딩 사이즈:  128 hidden size:  256\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 121s 404ms/step - loss: 3.3043 - val_loss: 2.4386\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.3973 - val_loss: 2.2853\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.2590 - val_loss: 2.2146\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.1883 - val_loss: 2.1753\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.1387 - val_loss: 2.1474\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 115s 401ms/step - loss: 2.0952 - val_loss: 2.1276\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.0587 - val_loss: 2.1132\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.0162 - val_loss: 2.1040\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 1.9855 - val_loss: 2.0970\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 116s 405ms/step - loss: 1.9414 - val_loss: 2.0952\n",
      "임베딩 사이즈:  128 hidden size:  512\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 139s 465ms/step - loss: 3.3171 - val_loss: 2.4202\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.3858 - val_loss: 2.2852\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.2639 - val_loss: 2.2201\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.1945 - val_loss: 2.1767\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.1432 - val_loss: 2.1492\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.0989 - val_loss: 2.1305\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.0625 - val_loss: 2.1160\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.0245 - val_loss: 2.1046\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 114s 400ms/step - loss: 1.9880 - val_loss: 2.0972\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 1.9479 - val_loss: 2.0961\n",
      "임베딩 사이즈:  128 hidden size:  1024\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 121s 404ms/step - loss: 3.3105 - val_loss: 2.4249\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.3850 - val_loss: 2.2909\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.2665 - val_loss: 2.2220\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 2.1959 - val_loss: 2.1777\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 117s 407ms/step - loss: 2.1419 - val_loss: 2.1497\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 128s 446ms/step - loss: 2.0992 - val_loss: 2.1285\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 123s 429ms/step - loss: 2.0614 - val_loss: 2.1148\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 115s 401ms/step - loss: 2.0206 - val_loss: 2.1040\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 1.9870 - val_loss: 2.0962\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 1.9476 - val_loss: 2.0917\n",
      "임베딩 사이즈:  128 hidden size:  2408\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 120s 402ms/step - loss: 3.3361 - val_loss: 2.4232\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 2.3798 - val_loss: 2.2800\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 115s 401ms/step - loss: 2.2611 - val_loss: 2.2145\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 115s 402ms/step - loss: 2.1874 - val_loss: 2.1747\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.1363 - val_loss: 2.1468\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 2.0962 - val_loss: 2.1275\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 115s 400ms/step - loss: 2.0591 - val_loss: 2.1163\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 114s 398ms/step - loss: 2.0154 - val_loss: 2.1050\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 114s 398ms/step - loss: 1.9795 - val_loss: 2.0982\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 115s 403ms/step - loss: 1.9493 - val_loss: 2.0937\n",
      "임베딩 사이즈:  256 hidden size:  256\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 118s 394ms/step - loss: 3.3140 - val_loss: 2.4165\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 134s 470ms/step - loss: 2.3746 - val_loss: 2.2790\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 115s 401ms/step - loss: 2.2621 - val_loss: 2.2158\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 113s 394ms/step - loss: 2.1974 - val_loss: 2.1766\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 178s 622ms/step - loss: 2.1380 - val_loss: 2.1500\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.1033 - val_loss: 2.1306\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0665 - val_loss: 2.1162\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0244 - val_loss: 2.1067\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.9891 - val_loss: 2.1010\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 1.9502 - val_loss: 2.0970\n",
      "임베딩 사이즈:  256 hidden size:  512\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 117s 390ms/step - loss: 3.3204 - val_loss: 2.4128\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.3709 - val_loss: 2.2787\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.2523 - val_loss: 2.2119\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.1899 - val_loss: 2.1740\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 111s 390ms/step - loss: 2.1398 - val_loss: 2.1477\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.0882 - val_loss: 2.1276\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 112s 391ms/step - loss: 2.0587 - val_loss: 2.1152\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 137s 479ms/step - loss: 2.0211 - val_loss: 2.1033\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 116s 404ms/step - loss: 1.9804 - val_loss: 2.0962\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 140s 491ms/step - loss: 1.9408 - val_loss: 2.0955\n",
      "임베딩 사이즈:  256 hidden size:  1024\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 141s 476ms/step - loss: 3.2991 - val_loss: 2.4209\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.3814 - val_loss: 2.2808\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.2655 - val_loss: 2.2151\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.1943 - val_loss: 2.1756\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.1380 - val_loss: 2.1491\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0992 - val_loss: 2.1283\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0629 - val_loss: 2.1136\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.0190 - val_loss: 2.1058\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9842 - val_loss: 2.0960\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.9482 - val_loss: 2.0939\n",
      "임베딩 사이즈:  256 hidden size:  2408\n",
      "WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 116s 390ms/step - loss: 3.3135 - val_loss: 2.4240\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.3724 - val_loss: 2.2837\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.2648 - val_loss: 2.2187\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.1913 - val_loss: 2.1758\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.1437 - val_loss: 2.1468\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 112s 390ms/step - loss: 2.0953 - val_loss: 2.1285\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 142s 497ms/step - loss: 2.0515 - val_loss: 2.1131\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.0204 - val_loss: 2.1055\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9837 - val_loss: 2.0976\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 1.9421 - val_loss: 2.0949\n",
      "임베딩 사이즈:  512 hidden size:  256\n",
      "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 115s 387ms/step - loss: 3.3191 - val_loss: 2.4299\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.3830 - val_loss: 2.2884\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 110s 385ms/step - loss: 2.2637 - val_loss: 2.2207\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 111s 386ms/step - loss: 2.1939 - val_loss: 2.1777\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 110s 385ms/step - loss: 2.1476 - val_loss: 2.1504\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 386ms/step - loss: 2.1009 - val_loss: 2.1281\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.0658 - val_loss: 2.1126\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 386ms/step - loss: 2.0216 - val_loss: 2.1029\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 110s 385ms/step - loss: 1.9867 - val_loss: 2.0957\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9482 - val_loss: 2.0917\n",
      "임베딩 사이즈:  512 hidden size:  512\n",
      "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 116s 389ms/step - loss: 3.2725 - val_loss: 2.4147\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.3767 - val_loss: 2.2798\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.2555 - val_loss: 2.2142\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.1899 - val_loss: 2.1717\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.1368 - val_loss: 2.1440\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0915 - val_loss: 2.1276\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0508 - val_loss: 2.1108\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0127 - val_loss: 2.1027\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.9735 - val_loss: 2.0954\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 1.9350 - val_loss: 2.0930\n",
      "임베딩 사이즈:  512 hidden size:  1024\n",
      "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 117s 390ms/step - loss: 3.3296 - val_loss: 2.4581\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 112s 391ms/step - loss: 2.4052 - val_loss: 2.2982\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 114s 400ms/step - loss: 2.2799 - val_loss: 2.2272\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 120s 420ms/step - loss: 2.2081 - val_loss: 2.1838\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 110s 386ms/step - loss: 2.1560 - val_loss: 2.1553\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.1119 - val_loss: 2.1354\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0690 - val_loss: 2.1200\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.0378 - val_loss: 2.1112\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0034 - val_loss: 2.1016\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.9629 - val_loss: 2.0971\n",
      "임베딩 사이즈:  512 hidden size:  2408\n",
      "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/10\n",
      "286/286 [==============================] - 117s 392ms/step - loss: 3.3258 - val_loss: 2.4449\n",
      "Epoch 2/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 2.3922 - val_loss: 2.2861\n",
      "Epoch 3/10\n",
      "286/286 [==============================] - 112s 391ms/step - loss: 2.2713 - val_loss: 2.2223\n",
      "Epoch 4/10\n",
      "286/286 [==============================] - 120s 419ms/step - loss: 2.1989 - val_loss: 2.1822\n",
      "Epoch 5/10\n",
      "286/286 [==============================] - 119s 417ms/step - loss: 2.1516 - val_loss: 2.1538\n",
      "Epoch 6/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.1036 - val_loss: 2.1338\n",
      "Epoch 7/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 2.0620 - val_loss: 2.1187\n",
      "Epoch 8/10\n",
      "286/286 [==============================] - 111s 387ms/step - loss: 2.0307 - val_loss: 2.1086\n",
      "Epoch 9/10\n",
      "286/286 [==============================] - 111s 389ms/step - loss: 1.9952 - val_loss: 2.1000\n",
      "Epoch 10/10\n",
      "286/286 [==============================] - 111s 388ms/step - loss: 1.9551 - val_loss: 2.0970\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for e_size in embedding_sizes:\n",
    "    for h_size in hidden_sizes:\n",
    "        print('임베딩 사이즈: ', e_size, 'hidden size: ', h_size)\n",
    "        model = GenerateLyrics(corpus, TextGenerator)\n",
    "        model.embedding_size = e_size\n",
    "        model.hidden_size = h_size\n",
    "        hist = model.fit(10)\n",
    "        result = model.generate_text(init_sentence=\"<start> i love\", max_len=15)\n",
    "        history.append((e_size, h_size, hist.history['loss'], hist.history['val_loss'], result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ordered-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"hist.pkl\"\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(history, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dying-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"hist.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "loaded_list = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "large-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512,\n",
       "  256,\n",
       "  1.9578521251678467,\n",
       "  2.0916693210601807,\n",
       "  '<start> i love you so much <end> '),\n",
       " (128,\n",
       "  1024,\n",
       "  1.9552738666534424,\n",
       "  2.0917131900787354,\n",
       "  '<start> i love you so much <end> '),\n",
       " (512,\n",
       "  512,\n",
       "  1.9445419311523438,\n",
       "  2.0930423736572266,\n",
       "  '<start> i love you , i love you <end> '),\n",
       " (128,\n",
       "  2408,\n",
       "  1.952721357345581,\n",
       "  2.09371018409729,\n",
       "  '<start> i love you , i love you <end> '),\n",
       " (256,\n",
       "  1024,\n",
       "  1.9537256956100464,\n",
       "  2.0939223766326904,\n",
       "  '<start> i love you so much , i love you <end> '),\n",
       " (64,\n",
       "  2408,\n",
       "  1.9582383632659912,\n",
       "  2.094468593597412,\n",
       "  \"<start> i love you , baby , i ' m <unk> ' <end> \"),\n",
       " (64,\n",
       "  256,\n",
       "  1.955055832862854,\n",
       "  2.0946004390716553,\n",
       "  '<start> i love you so much <end> '),\n",
       " (256,\n",
       "  2408,\n",
       "  1.9518351554870605,\n",
       "  2.0948731899261475,\n",
       "  '<start> i love you , i love you <end> '),\n",
       " (128,\n",
       "  256,\n",
       "  1.9495058059692383,\n",
       "  2.0952036380767822,\n",
       "  '<start> i love you , i love you , i love you <end> '),\n",
       " (256,\n",
       "  512,\n",
       "  1.9534275531768799,\n",
       "  2.0955021381378174,\n",
       "  '<start> i love you , i love you <end> '),\n",
       " (64,\n",
       "  512,\n",
       "  1.9540915489196777,\n",
       "  2.0955193042755127,\n",
       "  '<start> i love you , i love you <end> '),\n",
       " (64,\n",
       "  1024,\n",
       "  1.9527671337127686,\n",
       "  2.095975637435913,\n",
       "  '<start> i love you , baby , <end> '),\n",
       " (128,\n",
       "  512,\n",
       "  1.9579133987426758,\n",
       "  2.0961074829101562,\n",
       "  '<start> i love you so much <end> '),\n",
       " (512,\n",
       "  2408,\n",
       "  1.963467001914978,\n",
       "  2.0970213413238525,\n",
       "  \"<start> i love you , baby , i ' m <unk> ' <end> \"),\n",
       " (256,\n",
       "  256,\n",
       "  1.9591878652572632,\n",
       "  2.0970423221588135,\n",
       "  \"<start> i love you , i ' m <unk> <end> \"),\n",
       " (512,\n",
       "  1024,\n",
       "  1.9721777439117432,\n",
       "  2.097104549407959,\n",
       "  '<start> i love you , baby , baby , baby <end> ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist2 = [(x[0], x[1], x[2][-1], x[3][-1], x[4]) for x in history]\n",
    "hist2.sort(key=lambda x: x[3])\n",
    "hist2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-instruction",
   "metadata": {},
   "source": [
    "임베딩 사이즈: 512, hidden size: 256일 때, 가장 낮은 Validation loss 2.092를 기록했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-basket",
   "metadata": {},
   "source": [
    "## 정리\n",
    "1. 정규표현식을 활용하여 특수문자를 제거했습니다.\n",
    "- 중복 문장을 제거했습니다. \n",
    "- 피처링을 표시하는 \\[가수명\\] 문자그룹을 제거했습니다.\n",
    "- 기타 특수문자를 제거했습니다.\n",
    "2. 가장 낮은 validation loss는 임베딩 사이즈: 512, hidden size: 256일 때, 가장 낮은 Validation loss 2.092를 기록했습니다.\n",
    "3. 텍스트 제너레이션 결과는 위 항목과 같습니다. 가장 낮은 Validation loss를 기록했을 때의 텍스트 제너레이션 결과는 'i love' 입력 시, 'i love you so much' 입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
