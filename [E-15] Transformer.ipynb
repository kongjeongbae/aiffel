{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lucky-consideration",
   "metadata": {},
   "source": [
    "# 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "particular-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-brunswick",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "median-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-reunion",
   "metadata": {},
   "source": [
    "# scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "light-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-territory",
   "metadata": {},
   "source": [
    "# MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acute-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-highland",
   "metadata": {},
   "source": [
    "# Padding mask & Look ahead mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "roman-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-wheat",
   "metadata": {},
   "source": [
    "# 인코더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dying-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorporate-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-sender",
   "metadata": {},
   "source": [
    "# 디코더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wired-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beginning-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-economics",
   "metadata": {},
   "source": [
    "# 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "exciting-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"transformer_chatbot/data/ChatbotData .csv\")\n",
    "questions = data[\"Q\"].tolist()\n",
    "answers = data[\"A\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "surface-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [word.replace(\"?\", \"\").replace(\"!\", \"\").replace(\".\", \"\").replace(\",\", \"\") for word in questions]\n",
    "answers = [word.replace(\"?\", \"\").replace(\"!\", \"\").replace(\".\", \"\").replace(\",\", \"\") for word in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "legislative-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "working-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "executed-mainland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8190]\n",
      "END_TOKEN의 번호 : [8191]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "established-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "chubby-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 확실한 건 뭘까\n",
      "가장 확실한 시간은 오늘이에요 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요\n",
      "정수 인코딩 후의 22번째 질문 샘플: [379, 804, 37, 407]\n",
      "정수 인코딩 후의 22번째 답변 샘플: [379, 804, 907, 6543, 5090, 7615, 1110, 7806, 341, 5601, 41]\n"
     ]
    }
   ],
   "source": [
    "print(questions[22])\n",
    "print(answers[22])\n",
    "\n",
    "question_sample = tokenizer.encode(questions[22])\n",
    "answer_sample = tokenizer.encode(answers[22])\n",
    "print(f'정수 인코딩 후의 22번째 질문 샘플: {question_sample}')\n",
    "print(f'정수 인코딩 후의 22번째 답변 샘플: {answer_sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "brave-property",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sitting-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "signed-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8192\n",
      "필터링 후의 질문 샘플 개수: 9927\n",
      "필터링 후의 답변 샘플 개수: 9927\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :', VOCAB_SIZE)\n",
    "print(f'필터링 후의 질문 샘플 개수: {len(questions)}')\n",
    "print(f'필터링 후의 답변 샘플 개수: {len(answers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "canadian-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-intent",
   "metadata": {},
   "source": [
    "# 모델 정의 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "complicated-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "developed-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3151360     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3678720     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8192)   2105344     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,935,424\n",
      "Trainable params: 8,935,424\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "veterinary-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "artificial-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "rising-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "intelligent-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cross-subdivision",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 4.4625 - accuracy: 0.1111\n",
      "Epoch 2/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 3.9733 - accuracy: 0.1111\n",
      "Epoch 3/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 3.6904 - accuracy: 0.1142\n",
      "Epoch 4/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 3.4571 - accuracy: 0.1270\n",
      "Epoch 5/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 3.2466 - accuracy: 0.1399\n",
      "Epoch 6/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 3.0302 - accuracy: 0.1578\n",
      "Epoch 7/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 2.7899 - accuracy: 0.1826\n",
      "Epoch 8/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 2.5241 - accuracy: 0.2131\n",
      "Epoch 9/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 2.2388 - accuracy: 0.2452\n",
      "Epoch 10/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 1.9385 - accuracy: 0.2808\n",
      "Epoch 11/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 1.6323 - accuracy: 0.3183\n",
      "Epoch 12/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 1.3364 - accuracy: 0.3595\n",
      "Epoch 13/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 1.0608 - accuracy: 0.3988\n",
      "Epoch 14/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 0.8095 - accuracy: 0.4382\n",
      "Epoch 15/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 0.5975 - accuracy: 0.4733\n",
      "Epoch 16/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 0.4354 - accuracy: 0.5012\n",
      "Epoch 17/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 0.3081 - accuracy: 0.5245\n",
      "Epoch 18/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 0.2242 - accuracy: 0.5387\n",
      "Epoch 19/20\n",
      "156/156 [==============================] - 10s 62ms/step - loss: 0.1711 - accuracy: 0.5481\n",
      "Epoch 20/20\n",
      "156/156 [==============================] - 10s 61ms/step - loss: 0.1472 - accuracy: 0.5514\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "secret-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"loss plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-motor",
   "metadata": {},
   "source": [
    "# 문장 출력 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "characteristic-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.replace(\".\", \"\").replace(\",\", \"\").replace(\"!\", \"\").replace(\"?\", \"\").strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "prime-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "spiritual-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print(f'입력 : {sentence}')\n",
    "    print(f'출력 : {predicted_sentence}')\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-grave",
   "metadata": {},
   "source": [
    "# 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "lovely-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 반갑습니다\n",
      "출력 : 저도 반가워요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 반가워요'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('반갑습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fancy-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨가 안좋아요\n",
      "출력 : 마음도 추운가요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음도 추운가요'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 날씨가 안좋아요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "signed-retro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 열심히 공부합시다\n",
      "출력 : 그렇게 생각하는 사람 만나지 마세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그렇게 생각하는 사람 만나지 마세요'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('열심히 공부합시다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "attended-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 여행가고 싶다\n",
      "출력 : 계획을 세워보세요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'계획을 세워보세요'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('여행가고 싶다')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
